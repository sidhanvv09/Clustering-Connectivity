{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a25240b-c642-4ce5-bf87-a068eafb8750",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\academy\\OneDrive - IIT Delhi\\3. IIT DELHI\\2. Academics\\1_PAPER\\2_Analysis\n"
     ]
    }
   ],
   "source": [
    "# Directories\n",
    "import os\n",
    "os.chdir(r\"E:\\academy\\OneDrive - IIT Delhi\\3. IIT DELHI\\2. Academics\\1_PAPER\\2_Analysis\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fec69aef-d1f6-4361-8122-cef0f50becf7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sstar\\anaconda3\\envs\\imed\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "#Array packages\n",
    "import cartopy.crs as ccrs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import netCDF4 as nc4\n",
    "\n",
    "from scipy.stats import kendalltau\n",
    "import pymannkendall as mk\n",
    "\n",
    "#plots\n",
    "import matplotlib.pyplot as plt\n",
    "import rioxarray as rio\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import mapping\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "#Progress meter\n",
    "from dask.diagnostics import ProgressBar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Directories\n",
    "import os\n",
    "import glob\n",
    "import dask\n",
    "#import h5netcdf\n",
    "import scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a799cc4a-6796-4b1c-9a54-737a395fe553",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl=5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e79149-faa2-4105-9bf6-0ffaafefd20d",
   "metadata": {},
   "source": [
    "## 1 Full timeseries\n",
    "\n",
    "Lis outpt conversion\n",
    "Lis output - kg/m2s = lis *60*60*24 mm/day"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfec010-1a73-4e3d-8d59-88d254d46823",
   "metadata": {},
   "source": [
    "#### 1.1 Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55c7fef9-a1f7-45da-8498-94f6024737b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model=[\"LIS_MERRA2\",\"LIS_IMD\",\"LIS_CHIRPS\",\"LIS_ERA5\",\"LIS_IMDc\",\"LIS_IMDcnew\"]\n",
    "var=['TotalPrecip_tavg','Evap_tavg','Qs_tavg','Qsb_tavg']\n",
    "\n",
    "lsm = xr.open_mfdataset(f\"DATA_p/{model[mdl]}_1980_2021.nc\",engine='netcdf4', parallel=True,chunks={'time': 'auto'})\n",
    "lsm=lsm[var]\n",
    "#lsm=lsm.drop_vars('spatial_ref')\n",
    "lsm=lsm*60*60*24*30  # This 30 comes because we accidently averaged the daily to instead of doingg accumulated sum in HPC\n",
    "lsm=lsm.where(lsm>=0) # removin g negatives\n",
    "lsm=lsm.where((lsm>=0.1)|(lsm.isnull()),0) #isnull is to make the outer location nans remains nan\n",
    "\n",
    "lsm_re=lsm.where(lsm.TotalPrecip_tavg>=0.4)  # This only applied to calculate RE so that RE>1 can be removed\n",
    "lsm_re=lsm_re.where(~(lsm_re[\"Qs_tavg\"]>lsm_re[\"TotalPrecip_tavg\"]))\n",
    "\n",
    "#RE calculation\n",
    "RE=lsm_re[\"Qs_tavg\"]/lsm_re[\"TotalPrecip_tavg\"]\n",
    "RE=RE.where(~np.isinf(RE)) #converting inf to nan (inf effect all operation like mean, trend etc)\n",
    "RE=RE.where(RE<0.7).compute()\n",
    "\n",
    "lsm['RE']=RE\n",
    "\n",
    "\n",
    "#or linearly interpolate\n",
    "RE_fin=RE.interpolate_na(dim=\"lon\", method=\"linear\") # lat or lon is also fine\n",
    "#RE_fin=RE_fin.interpolate_na(dim=\"lat\", method=\"linear\")\n",
    "#RE_fin=RE_fin.interpolate_na(dim=\"time\", method=\"linear\")\n",
    "\n",
    "#Attaching seasonal mean\n",
    "RE_mn=RE.groupby(\"time.month\").mean()\n",
    "RE_mn = xr.concat([RE_mn]*len(np.unique(RE.time.dt.year)), dim=\"month\")\n",
    "RE_mn1=RE_mn.rename({'month': 'time'});RE_mn1[\"time\"]=RE.time\n",
    "RE_fin=RE_fin.combine_first(RE_mn1)\n",
    "\n",
    "\n",
    "RE_fin=RE_fin.where(~((RE.isnull()) & (lsm['TotalPrecip_tavg'].isnull())),RE) # This is to refil back the sorround nan values\n",
    "\n",
    "lsm['RE_cleaned']=RE_fin\n",
    "\n",
    "#lsm=lsm.drop_vars('spatial_ref')\n",
    "lsm.to_netcdf(f'DATA_p/LIS/{model[mdl]}/{model[mdl]}_grid_All.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0be37718-b33c-48c0-99d1-42ba21aa9d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsm.to_netcdf(f'DATA_p/LIS/{model[mdl]}/{model[mdl]}_grid_All.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f59e637-8e04-4e8f-a729-99114948de82",
   "metadata": {},
   "source": [
    "#### 1.2 Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6935f5d5-3346-4d56-9139-438048931e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_p=gpd.read_file('DATA_p/shapefile/south_asia_p.shp')\n",
    "dataset=[]\n",
    "lsm_R1=lsm\n",
    "for i in range(len(gdf_p.Basin)):\n",
    "    \n",
    "    B=gdf_p[gdf_p['Basin'] == gdf_p['Basin'][i]]\n",
    "    lsm_R1.rio.set_spatial_dims(y_dim=\"lat\",x_dim=\"lon\", inplace=True)\n",
    "    lsm_R1.rio.write_crs(\"EPSG:4326\", inplace=True)\n",
    "    lsm_clip = lsm_R1.rio.clip(B.geometry.apply(mapping), B.crs, drop=True)\n",
    "    A=lsm_clip.mean(dim=['lat','lon']).expand_dims(dim='region')\n",
    "    dataset.append(A)\n",
    "    \n",
    "lsm_R_all = xr.concat(dataset, dim='region')\n",
    "lsm_R_all['region'] = np.array(gdf_p.Basin)\n",
    "lsm_R_all.to_netcdf(f'DATA_p/LIS/{model[mdl]}/{model[mdl]}_reg_All.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e20f8d2-9eb4-4e0e-a7b3-275f4e1634e7",
   "metadata": {},
   "source": [
    "# 2 SPI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfc09ee-558a-48de-b878-d6f08782af6d",
   "metadata": {},
   "source": [
    "#### 2.1 grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ef01bab-f074-4ca4-b317-e140e8219943",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import climate_indices\n",
    "from climate_indices import indices\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "ds=lsm[['TotalPrecip_tavg','Qs_tavg','Evap_tavg','RE','RE_cleaned']].compute()\n",
    "\n",
    "\n",
    "ds=ds.where(ds!=0,0.001);ds=ds.where(ds>=0);\n",
    "da_precip_groupby = ds.stack(point=('lat', 'lon')).groupby('point')\n",
    "da_precip_groupby\n",
    "\n",
    "scale = 1\n",
    "distribution = climate_indices.indices.Distribution.gamma\n",
    "data_start_year = 1980\n",
    "calibration_year_initial = 1980\n",
    "calibration_year_final = 2021\n",
    "periodicity = periodicity = climate_indices.compute.Periodicity.monthly\n",
    "\n",
    "da_spi = xr.apply_ufunc(indices.spi,\n",
    "                        da_precip_groupby,\n",
    "                        scale,\n",
    "                        distribution,\n",
    "                        data_start_year,\n",
    "                        calibration_year_initial,\n",
    "                        calibration_year_final,\n",
    "                        periodicity)\n",
    "\n",
    "# unstack the array back into original dimensions\n",
    "da_spi = da_spi.unstack('point')\n",
    "\n",
    "da_spi.to_netcdf(f'DATA_p/LIS/{model[mdl]}/{model[mdl]}_grid_SPI1.nc')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c19ae6-0f25-4f73-b696-ddaf1ab3b36a",
   "metadata": {},
   "source": [
    "#### 2.2 REGIONAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a321787a-4598-46d9-bb42-b19787319ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sstar\\AppData\\Local\\Temp\\ipykernel_30672\\1836767655.py:21: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  SPI = xr.apply_ufunc(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "from scipy.stats import gamma, norm\n",
    "def spi_cal(data,yr):\n",
    "    data1 = data.copy()\n",
    "\n",
    "    for i in range(12): \n",
    "        sq=np.arange(i, i + 12*yr, 12)\n",
    "        D=data1[sq]\n",
    "        D[D == 0] = 0.01\n",
    "        D1=D[~np.isnan(D)]\n",
    "        shape, loc, scale = gamma.fit(D1)\n",
    "        POE = 1-gamma.cdf(D, shape, loc, scale)\n",
    "        cdf_std = norm.cdf(norm.ppf(POE))\n",
    "        spi = norm.ppf(1 - cdf_std)\n",
    "        data1[sq]=spi\n",
    "    return data1\n",
    "\n",
    "\n",
    "ds1=lsm_R_all.compute()\n",
    "SPI = xr.apply_ufunc(\n",
    "    spi_cal,  # Function for wavelet transformation\n",
    "    ds1,  # Input dataset\n",
    "    input_core_dims=[['time']],  # Core dimensions of the input\n",
    "    output_core_dims=[['time']],  # Core dimensions of the output\n",
    "    vectorize=True,  # Treat each lat-lon pair as a separate input\n",
    "    dask='parallelized',  # Use parallelized computation if using Dask arrays\n",
    "    output_dtypes=[ds1.RE.dtype],  # Output data type\n",
    "    output_sizes={'time': len(ds1.time.values)},# Size of the output dimension\n",
    "    kwargs={'yr': len(np.unique(ds1['time.year']))}\n",
    ")\n",
    "SPI=SPI.where(~np.isinf(SPI),0)\n",
    "SPI.to_netcdf(f'DATA_p/LIS/{model[mdl]}/{model[mdl]}_reg_SPI1.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ea5e8039-2e87-44f3-820f-62d101bef509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body[data-theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.DataArray (region: 18)&gt; Size: 144B\n",
       "array([0.06857724, 0.25589823, 0.5080208 , 0.74392576, 0.74248765,\n",
       "       0.58761546, 0.64329049, 0.21103489, 0.47981322, 0.49971078,\n",
       "       0.58909048, 0.54863124, 0.25077406, 0.37901431, 0.28986268,\n",
       "       0.50130565, 0.30504611, 0.84604764])\n",
       "Coordinates:\n",
       "    spatial_ref  int32 4B 0\n",
       "  * region       (region) object 144B &#x27;Indus&#x27; &#x27;Ganga&#x27; ... &#x27;EFMP&#x27; &#x27;West Flowing&#x27;</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.DataArray</div><div class='xr-array-name'></div><ul class='xr-dim-list'><li><span class='xr-has-index'>region</span>: 18</li></ul></div><ul class='xr-sections'><li class='xr-section-item'><div class='xr-array-wrap'><input id='section-b7ff7710-af89-41b0-a2ad-c06d0beea0db' class='xr-array-in' type='checkbox' checked><label for='section-b7ff7710-af89-41b0-a2ad-c06d0beea0db' title='Show/hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-array-preview xr-preview'><span>0.06858 0.2559 0.508 0.7439 0.7425 ... 0.379 0.2899 0.5013 0.305 0.846</span></div><div class='xr-array-data'><pre>array([0.06857724, 0.25589823, 0.5080208 , 0.74392576, 0.74248765,\n",
       "       0.58761546, 0.64329049, 0.21103489, 0.47981322, 0.49971078,\n",
       "       0.58909048, 0.54863124, 0.25077406, 0.37901431, 0.28986268,\n",
       "       0.50130565, 0.30504611, 0.84604764])</pre></div></div></li><li class='xr-section-item'><input id='section-7adb83eb-9abd-432f-8bfe-affc2eb87352' class='xr-section-summary-in' type='checkbox'  checked><label for='section-7adb83eb-9abd-432f-8bfe-affc2eb87352' class='xr-section-summary' >Coordinates: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>spatial_ref</span></div><div class='xr-var-dims'>()</div><div class='xr-var-dtype'>int32</div><div class='xr-var-preview xr-preview'>0</div><input id='attrs-9a5adcfb-faeb-4bf1-b0c5-f4f8151106a3' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-9a5adcfb-faeb-4bf1-b0c5-f4f8151106a3' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-f3679657-3e75-4152-9bcc-0efb9ecfca66' class='xr-var-data-in' type='checkbox'><label for='data-f3679657-3e75-4152-9bcc-0efb9ecfca66' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>crs_wkt :</span></dt><dd>GEOGCS[&quot;WGS 84&quot;,DATUM[&quot;WGS_1984&quot;,SPHEROID[&quot;WGS 84&quot;,6378137,298.257223563,AUTHORITY[&quot;EPSG&quot;,&quot;7030&quot;]],AUTHORITY[&quot;EPSG&quot;,&quot;6326&quot;]],PRIMEM[&quot;Greenwich&quot;,0,AUTHORITY[&quot;EPSG&quot;,&quot;8901&quot;]],UNIT[&quot;degree&quot;,0.0174532925199433,AUTHORITY[&quot;EPSG&quot;,&quot;9122&quot;]],AXIS[&quot;Latitude&quot;,NORTH],AXIS[&quot;Longitude&quot;,EAST],AUTHORITY[&quot;EPSG&quot;,&quot;4326&quot;]]</dd><dt><span>semi_major_axis :</span></dt><dd>6378137.0</dd><dt><span>semi_minor_axis :</span></dt><dd>6356752.314245179</dd><dt><span>inverse_flattening :</span></dt><dd>298.257223563</dd><dt><span>reference_ellipsoid_name :</span></dt><dd>WGS 84</dd><dt><span>longitude_of_prime_meridian :</span></dt><dd>0.0</dd><dt><span>prime_meridian_name :</span></dt><dd>Greenwich</dd><dt><span>geographic_crs_name :</span></dt><dd>WGS 84</dd><dt><span>grid_mapping_name :</span></dt><dd>latitude_longitude</dd><dt><span>spatial_ref :</span></dt><dd>GEOGCS[&quot;WGS 84&quot;,DATUM[&quot;WGS_1984&quot;,SPHEROID[&quot;WGS 84&quot;,6378137,298.257223563,AUTHORITY[&quot;EPSG&quot;,&quot;7030&quot;]],AUTHORITY[&quot;EPSG&quot;,&quot;6326&quot;]],PRIMEM[&quot;Greenwich&quot;,0,AUTHORITY[&quot;EPSG&quot;,&quot;8901&quot;]],UNIT[&quot;degree&quot;,0.0174532925199433,AUTHORITY[&quot;EPSG&quot;,&quot;9122&quot;]],AXIS[&quot;Latitude&quot;,NORTH],AXIS[&quot;Longitude&quot;,EAST],AUTHORITY[&quot;EPSG&quot;,&quot;4326&quot;]]</dd><dt><span>GeoTransform :</span></dt><dd>68.00000381469727 0.09999847412109375 0.0 24.199982404708862 0.0 0.09999990463256836</dd></dl></div><div class='xr-var-data'><pre>array(0)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>region</span></div><div class='xr-var-dims'>(region)</div><div class='xr-var-dtype'>object</div><div class='xr-var-preview xr-preview'>&#x27;Indus&#x27; &#x27;Ganga&#x27; ... &#x27;West Flowing&#x27;</div><input id='attrs-25598504-b3db-4923-9aaa-a5e1f0ad32bb' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-25598504-b3db-4923-9aaa-a5e1f0ad32bb' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-bcf9ade1-71c1-4177-a6e4-416a401f018c' class='xr-var-data-in' type='checkbox'><label for='data-bcf9ade1-71c1-4177-a6e4-416a401f018c' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;Indus&#x27;, &#x27;Ganga&#x27;, &#x27;WFKS&#x27;, &#x27;Sabarmati&#x27;, &#x27;Mahi&#x27;, &#x27;Tapi&#x27;, &#x27;Narmada&#x27;,\n",
       "       &#x27;Brahmaputra&#x27;, &#x27;Subarnarekha&#x27;, &#x27;Brahmani&#x27;, &#x27;Mahanadi&#x27;, &#x27;Godavari&#x27;,\n",
       "       &#x27;Krishna&#x27;, &#x27;Penanr&#x27;, &#x27;Cauvery&#x27;, &#x27;EFPK&#x27;, &#x27;EFMP&#x27;, &#x27;West Flowing&#x27;],\n",
       "      dtype=object)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-65554ec5-e308-4d88-afbf-b9bf0a3eaae3' class='xr-section-summary-in' type='checkbox'  ><label for='section-65554ec5-e308-4d88-afbf-b9bf0a3eaae3' class='xr-section-summary' >Indexes: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>region</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-49d567be-20c1-4136-8f75-edf54a08c92d' class='xr-index-data-in' type='checkbox'/><label for='index-49d567be-20c1-4136-8f75-edf54a08c92d' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([&#x27;Indus&#x27;, &#x27;Ganga&#x27;, &#x27;WFKS&#x27;, &#x27;Sabarmati&#x27;, &#x27;Mahi&#x27;, &#x27;Tapi&#x27;, &#x27;Narmada&#x27;,\n",
       "       &#x27;Brahmaputra&#x27;, &#x27;Subarnarekha&#x27;, &#x27;Brahmani&#x27;, &#x27;Mahanadi&#x27;, &#x27;Godavari&#x27;,\n",
       "       &#x27;Krishna&#x27;, &#x27;Penanr&#x27;, &#x27;Cauvery&#x27;, &#x27;EFPK&#x27;, &#x27;EFMP&#x27;, &#x27;West Flowing&#x27;],\n",
       "      dtype=&#x27;object&#x27;, name=&#x27;region&#x27;))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-45da301c-6da0-4275-886c-3c71b7cc5d1d' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-45da301c-6da0-4275-886c-3c71b7cc5d1d' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.DataArray (region: 18)> Size: 144B\n",
       "array([0.06857724, 0.25589823, 0.5080208 , 0.74392576, 0.74248765,\n",
       "       0.58761546, 0.64329049, 0.21103489, 0.47981322, 0.49971078,\n",
       "       0.58909048, 0.54863124, 0.25077406, 0.37901431, 0.28986268,\n",
       "       0.50130565, 0.30504611, 0.84604764])\n",
       "Coordinates:\n",
       "    spatial_ref  int32 4B 0\n",
       "  * region       (region) object 144B 'Indus' 'Ganga' ... 'EFMP' 'West Flowing'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xr.corr(lsm_R_all.TotalPrecip_tavg,spi_reg.SPI_TotalPrecip_tavg,dim='time').compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d6454a-304e-4f5e-8b10-7cb3cf309f9c",
   "metadata": {},
   "source": [
    "# 3 Seasonal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78932ccb-18ce-42d1-a5b7-a7ae6c7ec8b1",
   "metadata": {},
   "source": [
    "#### 3.1 Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e42340d-023d-41f7-95d6-4e98752033d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "ssn=['Pre-monsoon','Monsoon','Post-monsoon','Winter']\n",
    "ssn_m=[[3,4,5],[6,7,8,9],[10,11],[12,1,2]]\n",
    "model=[\"LIS_MERRA2\",\"LIS_IMD\",\"LIS_CHIRPS\",\"LIS_ERA5\",\"LIS_IMDc\",\"LIS_IMDcnew\"]\n",
    "#var=['TotalPrecip_tavg','Evap_tavg','Qs_tavg']\n",
    "\n",
    "\n",
    "lsm = xr.open_mfdataset(f\"DATA_p/{model[mdl]}_1980_2021.nc\",engine='netcdf4', parallel=True,chunks={'time': 'auto'})\n",
    "#lsm=lsm.compute()\n",
    "lsm=lsm*60*60*24*30\n",
    "lsm=lsm.where(lsm>0)\n",
    "lsm_re=lsm.where((lsm>=0.1)|(lsm.isnull()),0) #is\n",
    "\n",
    "dataset=[]\n",
    "for ss in range(4):\n",
    "    if ss!=3:\n",
    "        lsm_ssn=lsm.sel(time=lsm[\"time.month\"].isin(ssn_m[ss]))\n",
    "        lsm_ssn=lsm_ssn.groupby(\"time.year\").mean(dim=\"time\")\n",
    "        print(\"1\")\n",
    "    else:\n",
    "        lsm_roll = lsm.rolling(time=3).mean()\n",
    "        lsm_ssn=lsm_roll.isel(time=lsm_roll[\"time.month\"].isin([1])).groupby(\"time.year\").mean()\n",
    "        lsm_ssn=lsm_ssn.where(lsm_ssn['year'] != 1980, lsm_ssn.isel(year=1))\n",
    "        print(\"3\")\n",
    "\n",
    "    lsm_re=lsm_ssn.where(lsm_ssn.TotalPrecip_tavg>=0.4) #isnull is to make the outer location nans remains nan\n",
    "    lsm_re1=lsm_re.where(~(lsm_ssn[\"Qs_tavg\"]>lsm_ssn[\"TotalPrecip_tavg\"]))\n",
    "     \n",
    "    RE=lsm_re1[\"Qs_tavg\"]/lsm_re1[\"TotalPrecip_tavg\"]\n",
    "    RE=RE.where(~np.isinf(RE)) #converting inf to nan (inf effect all operation like mean, trend etc)\n",
    "    RE=RE.where(RE<0.7).compute()\n",
    "    lsm_ssn['RE']=RE\n",
    "    \n",
    "    #Filling values \n",
    "\n",
    "    RE_fin=RE.interpolate_na(dim=\"lon\", method=\"linear\") # lat or lon is also fine\n",
    "    #RE_fin=RE_fin.interpolate_na(dim=\"lat\", method=\"linear\")\n",
    "    #RE_fin=RE_fin.interpolate_na(dim=\"year\", method=\"linear\")\n",
    "    \n",
    "    lsm_ssn['RE_cleaned']=RE_fin\n",
    "    \n",
    "    dataset.append(lsm_ssn.expand_dims(dim='season'))\n",
    "\n",
    "lsm_ssn = xr.concat(dataset, dim='season')\n",
    "lsm_ssn=lsm_ssn.assign_coords(season=ssn)\n",
    "\n",
    "\n",
    "#lsm_ssn=lsm_ssn.drop_vars('spatial_ref')\n",
    "lsm_ssn.to_netcdf(f'DATA_p/LIS/{model[mdl]}/{model[mdl]}_grid_ssn.nc')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4944cba0-3021-4dd0-bed0-8e929c78a510",
   "metadata": {},
   "source": [
    "#### 3.2 Regional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfb22c28-738f-428c-9eab-6212ce17d6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_p=gpd.read_file('DATA_p/shapefile/south_asia_p.shp')\n",
    "dataset=[]\n",
    "lsm_R2=lsm_ssn\n",
    "for i in range(len(gdf_p.Basin)):\n",
    "    \n",
    "    B=gdf_p[gdf_p['Basin'] == gdf_p['Basin'][i]]\n",
    "    lsm_R2.rio.set_spatial_dims(y_dim=\"lat\",x_dim=\"lon\", inplace=True)\n",
    "    lsm_R2.rio.write_crs(\"EPSG:4326\", inplace=True)\n",
    "    lsm_clip = lsm_R2.rio.clip(B.geometry.apply(mapping), B.crs, drop=True)\n",
    "    A=lsm_clip.mean(dim=['lat','lon']).expand_dims(dim='region')\n",
    "    dataset.append(A)\n",
    "    \n",
    "lsm_R_ssn = xr.concat(dataset, dim='region')\n",
    "lsm_R_ssn['region'] = np.array(gdf_p.Basin)\n",
    "lsm_R_ssn.to_netcdf(f'DATA_p/LIS/{model[mdl]}/{model[mdl]}_reg_ssn.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b019e15-9302-473e-944d-b46a050c9af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsm_R_ssn.to_netcdf(f'DATA_p/LIS/{model[mdl]}/{model[mdl]}_reg_ssn.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d09bf5-11f8-406c-83ce-20737dbfb1d8",
   "metadata": {},
   "source": [
    "#### 3.2 Regional seasonal spi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26c69894-6898-41c0-943c-448d34e9ef95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sstar\\AppData\\Local\\Temp\\ipykernel_30672\\996908936.py:32: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  lsm_reg_spi = xr.apply_ufunc(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "from scipy.stats import gamma, norm\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "var=['TotalPrecip_tavg','Evap_tavg','Qs_tavg','RE','RE_cleaned']\n",
    "# Define your function to calculate SPI\n",
    "def calculate_spi(data_n):\n",
    "    # Post-processing to handle NaNs and zeros\n",
    "\n",
    "    # Replace NaN values with themean \n",
    "    data_n= np.where(np.isnan(data_n), np.nanmean(data_n), data_n)\n",
    "    \n",
    "    data_n=np.nan_to_num(data_n, nan=0)\n",
    "    data_n = np.where((data_n == 0)|(data_n < 0), 0.01, data_n)  # Replace zeros with 0.01\n",
    "\n",
    "    # Fit gamma distribution\n",
    "    shape, loc, scale = gamma.fit(data_n, floc=0)\n",
    "\n",
    "    # Calculate Probability of Exceedance (POE)\n",
    "    POE = 1 - gamma.cdf(data_n, shape, loc, scale)\n",
    "\n",
    "    # Calculate Standard Normal Variate (SNV) or Standardized Precipitation Index (SPI)\n",
    "    cdf_std = norm.cdf(norm.ppf(POE))\n",
    "    spi = norm.ppf(1 - cdf_std)\n",
    "\n",
    "    return spi\n",
    "\n",
    "# Assuming you have already loaded your dataset `lsm_ssn` which has dimensions (region, year, season)\n",
    "\n",
    "lsm_R_ssn=lsm_R_ssn.chunk({'year': -1}) # Coree dimension should be planee \n",
    "lsm_reg_spi = xr.apply_ufunc(\n",
    "    calculate_spi,  # Function for wavelet transformation\n",
    "    lsm_R_ssn,  # Input dataset\n",
    "    input_core_dims=[['year']],  # Core dimensions of the input\n",
    "    output_core_dims=[['year']],  # Core dimensions of the output\n",
    "    vectorize=True,  # Treat each lat-lon pair as a separate input\n",
    "    dask='parallelized',  # Use parallelized computation if using Dask arrays\n",
    "    output_dtypes=[lsm_R_ssn.RE.dtype],  # Output data type\n",
    "    output_sizes={'year': len(lsm_R_ssn.year)}  # Size of the output dimension\n",
    ")\n",
    "\n",
    "lsm_reg_spi=lsm_reg_spi.where(~np.isinf(lsm_reg_spi),0)\n",
    "lsm_reg_spi.to_netcdf(f'DATA_p/LIS/{model[mdl]}/{model[mdl]}_reg_ssn_SPI1.nc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1d5226-ffa1-434c-b77d-639b57d741ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420ad2d4-7b00-4a55-9e71-c477ff1a219a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7075812f-ae5c-4aa5-a3d3-ed2d98270549",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69ff70f9-efd8-47f9-b55f-941d7e467869",
   "metadata": {},
   "source": [
    "## 2 Regional average of RE (Here first we calculate average ppt and qs of a region then calculate RE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "4b4fb278-5eea-4642-b61e-9ac3869d2cad",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sstar\\AppData\\Local\\Temp\\ipykernel_11368\\3816887693.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gdf_new.Basin[0:3]=['Brahmaputra','Ganga','Indus']\n",
      "C:\\Users\\sstar\\AppData\\Local\\Temp\\ipykernel_11368\\3816887693.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gdf_new.Basin[13]='West flowing'\n",
      "C:\\Users\\sstar\\AppData\\Local\\Temp\\ipykernel_11368\\3816887693.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gdf_new.Basin[14]='WFKS'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      Brahmaputra\n",
       "1            Ganga\n",
       "2            Indus\n",
       "3          Cauvery\n",
       "4         Godavari\n",
       "5          Krishna\n",
       "6         Mahanadi\n",
       "7             Mahi\n",
       "8          Narmada\n",
       "9           Pennar\n",
       "10       Sabarmati\n",
       "11    Subarnarekha\n",
       "12            Tapi\n",
       "13    West flowing\n",
       "14            WFKS\n",
       "15            EFMP\n",
       "16            EFPK\n",
       "Name: Basin, dtype: object"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf = gpd.read_file('DATA_p/Shapefiles/India_trans/India_trans_new.shp')\n",
    "\n",
    "#merging east flowing\n",
    "B1_merge = ['East_Flowing_M_G', 'East_Flowing_G_K', 'East_Flowing_K_P']\n",
    "bas1 = gdf[gdf['Basin'].isin(B1_merge)]\n",
    "m_geometry = bas1.geometry.unary_union;m_area = bas1.area.sum()\n",
    "M1 = gpd.GeoDataFrame({'Basin': ['EFMP'], 'SUB_AREA': [m_area],'UP_AREA': [m_area], 'geometry': [m_geometry]}, crs=gdf.crs)\n",
    "\n",
    "#merging east flowing\n",
    "B2_merge = ['East_Flowing_Cauvery', 'East_flowing_pennar']\n",
    "bas2 = gdf[gdf['Basin'].isin(B2_merge)]\n",
    "m_geometry = bas2.geometry.unary_union;m_area = bas2.area.sum()\n",
    "M2 = gpd.GeoDataFrame({'Basin': ['EFPK'], 'SUB_AREA': [m_area],'UP_AREA': [m_area], 'geometry': [m_geometry]}, crs=gdf.crs)\n",
    "\n",
    "## APPENDING THEM\n",
    "gdf_p = pd.concat([gdf, M1,M2], ignore_index=True)\n",
    "\n",
    "## Dropingg the basins\n",
    "B_drop=B1_merge+B2_merge+['east_flowing_mahdi_pnr','east_flowing_pnr_kanri','Brahmaputra','Ganga','Indus']\n",
    "gdf_p=gdf_p[~gdf_p.Basin.isin(B_drop)]\n",
    "\n",
    "gdf_p = gdf_p.reset_index(drop=True)\n",
    "gdf_p.Basin[0:3]=['Brahmaputra','Ganga','Indus']\n",
    "gdf_p.Basin[13]='West flowing'\n",
    "gdf_p.Basin[14]='WFKS'\n",
    "gdf_p.Basin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "007cc44f-ea2f-4368-985b-d53d05be75ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl=1\n",
    "ssn=['Pre-monsoon','Monsoon','Post-monsoon','Winter']\n",
    "ssn_m=[[3,4,5],[6,7,8,9],[10,11],[12,1,2]]\n",
    "model=[\"LIS_MERRA2\",\"LIS_IMD\",\"LIS_CHIRPS\",\"LIS_ERA5\",\"LIS_IMDc\"]\n",
    "var=['TotalPrecip_tavg','Evap_tavg','Qs_tavg','RE']\n",
    "\n",
    "\n",
    "lsm = xr.open_mfdataset(f\"DATA_p/{model[mdl]}_1980_2021.nc\",engine='netcdf4', parallel=True,chunks={'time': 'auto'})\n",
    "lsm=lsm[['TotalPrecip_tavg','Evap_tavg','Qs_tavg']].compute()\n",
    "lsm=lsm*60*60*24*30\n",
    "lsm=lsm.where(lsm>=0)\n",
    "\n",
    "\n",
    "dataset=[]\n",
    "for i in range(len(basin_new)):\n",
    "    \n",
    "    B=gdf[gdf['Basin'] == basin_new[i]]\n",
    "    lsm_R.rio.set_spatial_dims(y_dim=\"lat\",x_dim=\"lon\", inplace=True)\n",
    "    lsm.rio.write_crs(\"EPSG:4326\", inplace=True)\n",
    "    lsm_clip = lsm.rio.clip(B.geometry.apply(mapping), B.crs, drop=True)\n",
    "    A=lsm_clip.mean(dim=['lat','lon']).expand_dims(dim='region')\n",
    "    dataset.append(A)\n",
    "    \n",
    "lsm_R = xr.concat(dataset, dim='region')\n",
    "lsm_R['region'] = basin_new\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde07b42-fa53-4088-aff0-c8fc6af9f2a6",
   "metadata": {},
   "source": [
    "### 2.1 Full timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "5c78a753-1c4d-445f-bad5-b6b29e4ad112",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsm_R1=lsm_R.where(lsm_R.TotalPrecip_tavg>=1) #isnull is to make the outer location nans remains nan\n",
    "lsm_R1=lsm_R1.where(~(lsm_R1[\"Qs_tavg\"]>lsm_R1[\"TotalPrecip_tavg\"]))\n",
    "\n",
    "RE=lsm_R1[\"Qs_tavg\"]/lsm_R1[\"TotalPrecip_tavg\"]\n",
    "RE=RE.where(~np.isinf(RE)) #converting inf to nan (inf effect all operation like mean, trend etc)\n",
    "RE=RE.where(RE<0.7).compute()\n",
    "lsm_R['RE']=RE\n",
    "\n",
    "\n",
    "RE_mn=RE.groupby(\"time.month\").mean()\n",
    "RE_mn = xr.concat([RE_mn]*len(np.unique(RE.time.dt.year)), dim=\"month\")\n",
    "RE_mn1=RE_mn.rename({'month': 'time'});RE_mn1[\"time\"]=RE.time\n",
    "RE_fin=RE.combine_first(RE_mn1)\n",
    "\n",
    "\n",
    "lsm_R['RE_cleaned']=RE_fin\n",
    "\n",
    "lsm_R.to_netcdf(f'DATA_p/LIS/{model[mdl]}/{model[mdl]}_reg_All.nc')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f6115e-ba6e-4051-ba5d-e50a2f52a64c",
   "metadata": {},
   "source": [
    "### 2.2 Full timeseries SPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "ab2884c4-21ea-47a1-a791-6640d3497eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "from scipy.stats import gamma, norm\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "var=['TotalPrecip_tavg','Evap_tavg','Qs_tavg','RE','RE_cleaned']\n",
    "def calculate_spi(data):\n",
    "    # Post-processing to handle NaNs and zeros\n",
    "    data_n = data.copy()\n",
    "    data_n = data_n.fillna(data_n.mean())  # Fill NaNs with mean\n",
    "    data_n = xr.where(data_n == 0, 0.01, data_n)  # Replace zeros with 0.01\n",
    "\n",
    "    # Fit gamma distribution\n",
    "    shape, loc, scale = gamma.fit(data_n, floc=0)\n",
    "\n",
    "    # Calculate Probability of Exceedance (POE)\n",
    "    POE = 1 - gamma.cdf(data_n, shape, loc, scale)\n",
    "\n",
    "    # Calculate Standard Normal Variate (SNV) or Standardized Precipitation Index (SPI)\n",
    "    cdf_std = norm.cdf(norm.ppf(POE))\n",
    "    spi = norm.ppf(1 - cdf_std)\n",
    "\n",
    "    return spi\n",
    "\n",
    "\n",
    "result=[]\n",
    "for vr in var:\n",
    "\n",
    " ds=lsm_R[vr]\n",
    " spi = ds.groupby('time.month').apply(calculate_spi)\n",
    "\n",
    " # Create a new DataArray for SPI\n",
    " spi_ds = xr.DataArray(spi, coords=ds.coords, dims=ds.dims, name=f'SPI_{vr}')\n",
    " result.append(spi_ds)\n",
    "\n",
    "spi_reg = xr.merge(result)\n",
    "spi_reg.to_netcdf(f'DATA_p/LIS/{model[mdl]}/{model[mdl]}_reg_SPI1.nc')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ee743d-03ae-4f95-aa89-a3f469ddf846",
   "metadata": {},
   "source": [
    "### 2.3 Seasonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "14314777-75e1-41b8-9fa5-89d9830337b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "lsm=lsm_R\n",
    "dataset=[]\n",
    "for ss in range(4):\n",
    "    if ss!=3:\n",
    "        lsm_ssn=lsm.sel(time=lsm[\"time.month\"].isin(ssn_m[ss]))\n",
    "        lsm_ssn=lsm_ssn.groupby(\"time.year\").mean(dim=\"time\")\n",
    "        print(\"1\")\n",
    "    else:\n",
    "        lsm_roll = lsm.rolling(time=3).mean()\n",
    "        lsm_ssn=lsm_roll.isel(time=lsm_roll[\"time.month\"].isin([1])).groupby(\"time.year\").mean()\n",
    "        lsm_ssn=lsm_ssn.where(lsm_ssn['year'] != 1980, lsm_ssn.isel(year=1))\n",
    "        print(\"3\")\n",
    "\n",
    "\n",
    "    lsm_re=lsm_ssn.where(lsm_ssn.TotalPrecip_tavg>=0.4) #isnull is to make the outer location nans remains nan\n",
    "    lsm_re1=lsm_re.where(~(lsm_ssn[\"Qs_tavg\"]>lsm_ssn[\"TotalPrecip_tavg\"]))\n",
    "     \n",
    "    RE=lsm_re1[\"Qs_tavg\"]/lsm_re1[\"TotalPrecip_tavg\"]\n",
    "    RE=RE.where(~np.isinf(RE)) #converting inf to nan (inf effect all operation like mean, trend etc)\n",
    "    RE=RE.where(RE<0.7).compute()\n",
    "    lsm_ssn['RE']=RE\n",
    "    \n",
    "    #Preprocessing   \n",
    "    RE_fin=RE.interpolate_na(dim=\"year\", method=\"linear\",fill_value=\"extrapolate\") # lat or lon is also fine\n",
    "    lsm_ssn['RE_cleaned']=RE_fin\n",
    "    dataset.append(lsm_ssn.expand_dims(dim='season'))\n",
    "\n",
    "\n",
    "lsm_ssn = xr.concat(dataset, dim='season')\n",
    "lsm_ssn=lsm_ssn.assign_coords(season=ssn)\n",
    "\n",
    "\n",
    "lsm_ssn.to_netcdf(f'DATA_p/LIS/{model[mdl]}/{model[mdl]}_reg_ssn.nc')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4ae950-d8a2-41b0-9a02-f95d3e25750a",
   "metadata": {},
   "source": [
    "### 2.4 Seasonal SPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "c90a0044-44e7-4b89-aeef-1f56087ac314",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sstar\\AppData\\Local\\Temp\\ipykernel_11368\\1301548028.py:32: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  lsm_reg_spi = xr.apply_ufunc(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "from scipy.stats import gamma, norm\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "var=['TotalPrecip_tavg','Evap_tavg','Qs_tavg','RE','RE_cleaned']\n",
    "# Define your function to calculate SPI\n",
    "def calculate_spi(data_n):\n",
    "    # Post-processing to handle NaNs and zeros\n",
    "\n",
    "    # Replace NaN values with themean \n",
    "    data_n= np.where(np.isnan(data_n), np.nanmean(data_n), data_n)\n",
    "    \n",
    "    data_n=np.nan_to_num(data_n, nan=0)\n",
    "    data_n = np.where((data_n == 0)|(data_n < 0), 0.01, data_n)  # Replace zeros with 0.01\n",
    "\n",
    "    # Fit gamma distribution\n",
    "    shape, loc, scale = gamma.fit(data_n, floc=0)\n",
    "\n",
    "    # Calculate Probability of Exceedance (POE)\n",
    "    POE = 1 - gamma.cdf(data_n, shape, loc, scale)\n",
    "\n",
    "    # Calculate Standard Normal Variate (SNV) or Standardized Precipitation Index (SPI)\n",
    "    cdf_std = norm.cdf(norm.ppf(POE))\n",
    "    spi = norm.ppf(1 - cdf_std)\n",
    "\n",
    "    return spi\n",
    "\n",
    "# Assuming you have already loaded your dataset `lsm_ssn` which has dimensions (region, year, season)\n",
    "\n",
    "\n",
    "lsm_reg_spi = xr.apply_ufunc(\n",
    "    calculate_spi,  # Function for wavelet transformation\n",
    "    lsm_ssn,  # Input dataset\n",
    "    input_core_dims=[['year']],  # Core dimensions of the input\n",
    "    output_core_dims=[['year']],  # Core dimensions of the output\n",
    "    vectorize=True,  # Treat each lat-lon pair as a separate input\n",
    "    dask='parallelized',  # Use parallelized computation if using Dask arrays\n",
    "    output_dtypes=[ds.dtype],  # Output data type\n",
    "    output_sizes={'time': len(lsm_ssn.year)}  # Size of the output dimension\n",
    ")\n",
    "\n",
    "\n",
    "lsm_reg_spi.to_netcdf(f'DATA_p/LIS/{model[mdl]}/{model[mdl]}_reg_ssn_SPI1.nc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c0c7cd-1aaa-4d77-8c41-ca92457f4c09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca3a132-c27d-4d83-bb99-00c26175c5c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b67b257-5c43-492a-a3cc-6904b669b08b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75dbbd54-7898-4f9b-a59a-ca564a3bd0e2",
   "metadata": {},
   "source": [
    "# Practise session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "eb3bd4d9-ace8-408e-8caf-2d92a6787e04",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[138], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m vr \u001b[38;5;129;01min\u001b[39;00m var:\n\u001b[0;32m     29\u001b[0m  ds\u001b[38;5;241m=\u001b[39mlsm_R_all[vr]\n\u001b[1;32m---> 30\u001b[0m  spi \u001b[38;5;241m=\u001b[39m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtime.month\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcalculate_spi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m  \u001b[38;5;66;03m# Create a new DataArray for SPI\u001b[39;00m\n\u001b[0;32m     33\u001b[0m  spi_ds \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mDataArray(spi, coords\u001b[38;5;241m=\u001b[39mds\u001b[38;5;241m.\u001b[39mcoords, dims\u001b[38;5;241m=\u001b[39mds\u001b[38;5;241m.\u001b[39mdims, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSPI_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\imed\\Lib\\site-packages\\xarray\\core\\groupby.py:1488\u001b[0m, in \u001b[0;36mDataArrayGroupByBase.apply\u001b[1;34m(self, func, shortcut, args, **kwargs)\u001b[0m\n\u001b[0;32m   1476\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1477\u001b[0m \u001b[38;5;124;03mBackward compatible implementation of ``map``\u001b[39;00m\n\u001b[0;32m   1478\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1481\u001b[0m \u001b[38;5;124;03mDataArrayGroupBy.map\u001b[39;00m\n\u001b[0;32m   1482\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1483\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1484\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGroupBy.apply may be deprecated in the future. Using GroupBy.map is encouraged\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1485\u001b[0m     \u001b[38;5;167;01mPendingDeprecationWarning\u001b[39;00m,\n\u001b[0;32m   1486\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   1487\u001b[0m )\n\u001b[1;32m-> 1488\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshortcut\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshortcut\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\imed\\Lib\\site-packages\\xarray\\core\\groupby.py:1454\u001b[0m, in \u001b[0;36mDataArrayGroupByBase.map\u001b[1;34m(self, func, args, shortcut, **kwargs)\u001b[0m\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\n\u001b[0;32m   1407\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1408\u001b[0m     func: Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, DataArray],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1411\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   1412\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataArray:\n\u001b[0;32m   1413\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Apply a function to each array in the group and concatenate them\u001b[39;00m\n\u001b[0;32m   1414\u001b[0m \u001b[38;5;124;03m    together into a new array.\u001b[39;00m\n\u001b[0;32m   1415\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1452\u001b[0m \u001b[38;5;124;03m        The result of splitting, applying and combining this array.\u001b[39;00m\n\u001b[0;32m   1453\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1454\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_maybe_warn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarn_squeeze\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshortcut\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshortcut\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m   1456\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\imed\\Lib\\site-packages\\xarray\\core\\groupby.py:1473\u001b[0m, in \u001b[0;36mDataArrayGroupByBase._map_maybe_warn\u001b[1;34m(self, func, args, warn_squeeze, shortcut, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m grouped \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1468\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_grouped_shortcut(warn_squeeze)\n\u001b[0;32m   1469\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shortcut\n\u001b[0;32m   1470\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_grouped(warn_squeeze)\n\u001b[0;32m   1471\u001b[0m )\n\u001b[0;32m   1472\u001b[0m applied \u001b[38;5;241m=\u001b[39m (maybe_wrap_array(arr, func(arr, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)) \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m grouped)\n\u001b[1;32m-> 1473\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_combine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapplied\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshortcut\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshortcut\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\imed\\Lib\\site-packages\\xarray\\core\\groupby.py:1492\u001b[0m, in \u001b[0;36mDataArrayGroupByBase._combine\u001b[1;34m(self, applied, shortcut)\u001b[0m\n\u001b[0;32m   1490\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_combine\u001b[39m(\u001b[38;5;28mself\u001b[39m, applied, shortcut\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   1491\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Recombine the applied objects like the original.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1492\u001b[0m     applied_example, applied \u001b[38;5;241m=\u001b[39m \u001b[43mpeek_at\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapplied\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1493\u001b[0m     coord, dim, positions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_infer_concat_args(applied_example)\n\u001b[0;32m   1494\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shortcut:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\imed\\Lib\\site-packages\\xarray\\core\\utils.py:205\u001b[0m, in \u001b[0;36mpeek_at\u001b[1;34m(iterable)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the first value from iterable, as well as a new iterator with\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;124;03mthe same content as the original iterable\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    204\u001b[0m gen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(iterable)\n\u001b[1;32m--> 205\u001b[0m peek \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(gen)\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m peek, itertools\u001b[38;5;241m.\u001b[39mchain([peek], gen)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\imed\\Lib\\site-packages\\xarray\\core\\groupby.py:1472\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1458\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_map_maybe_warn\u001b[39m(\n\u001b[0;32m   1459\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1460\u001b[0m     func: Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, DataArray],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1465\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   1466\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataArray:\n\u001b[0;32m   1467\u001b[0m     grouped \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1468\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_grouped_shortcut(warn_squeeze)\n\u001b[0;32m   1469\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m shortcut\n\u001b[0;32m   1470\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_grouped(warn_squeeze)\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[1;32m-> 1472\u001b[0m     applied \u001b[38;5;241m=\u001b[39m (maybe_wrap_array(arr, \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m grouped)\n\u001b[0;32m   1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine(applied, shortcut\u001b[38;5;241m=\u001b[39mshortcut)\n",
      "Cell \u001b[1;32mIn[138], line 14\u001b[0m, in \u001b[0;36mcalculate_spi\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     11\u001b[0m data_n \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mwhere(data_n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0.01\u001b[39m, data_n)  \u001b[38;5;66;03m# Replace zeros with 0.01\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Fit gamma distribution\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m shape, loc, scale \u001b[38;5;241m=\u001b[39m \u001b[43mgamma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_n\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfloc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Calculate Probability of Exceedance (POE)\u001b[39;00m\n\u001b[0;32m     17\u001b[0m POE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m gamma\u001b[38;5;241m.\u001b[39mcdf(data_n, shape, loc, scale)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\imed\\Lib\\site-packages\\scipy\\stats\\_continuous_distns.py:3022\u001b[0m, in \u001b[0;36mgamma_gen.fit\u001b[1;34m(self, data, *args, **kwds)\u001b[0m\n\u001b[0;32m   3018\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll parameters fixed. There is nothing to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3019\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimize.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3021\u001b[0m \u001b[38;5;66;03m# Fixed location is handled by shifting the data.\u001b[39;00m\n\u001b[1;32m-> 3022\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(data)\n\u001b[0;32m   3024\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(data)\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m   3025\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe data contains non-finite values.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\imed\\Lib\\site-packages\\xarray\\core\\common.py:166\u001b[0m, in \u001b[0;36mAbstractArray.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m: Any, dtype: DTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m--> 166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\imed\\Lib\\site-packages\\xarray\\core\\dataarray.py:770\u001b[0m, in \u001b[0;36mDataArray.values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalues\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m    763\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    764\u001b[0m \u001b[38;5;124;03m    The array's data as a numpy.ndarray.\u001b[39;00m\n\u001b[0;32m    765\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    768\u001b[0m \u001b[38;5;124;03m    type does not support coercion like this (e.g. cupy).\u001b[39;00m\n\u001b[0;32m    769\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 770\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\imed\\Lib\\site-packages\\xarray\\core\\variable.py:508\u001b[0m, in \u001b[0;36mVariable.values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalues\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    507\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"The variable's data as a numpy.ndarray\"\"\"\u001b[39;00m\n\u001b[1;32m--> 508\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_as_array_or_item\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\imed\\Lib\\site-packages\\xarray\\core\\variable.py:306\u001b[0m, in \u001b[0;36m_as_array_or_item\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_as_array_or_item\u001b[39m(data):\n\u001b[0;32m    293\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the given values as a numpy array, or as an individual item if\u001b[39;00m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;124;03m    it's a 0d datetime64 or timedelta64 array.\u001b[39;00m\n\u001b[0;32m    295\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;124;03m    TODO: remove this (replace with np.asarray) once these issues are fixed\u001b[39;00m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 306\u001b[0m     data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(data)\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\imed\\Lib\\site-packages\\dask\\array\\core.py:1626\u001b[0m, in \u001b[0;36mArray.__array__\u001b[1;34m(self, dtype, **kwargs)\u001b[0m\n\u001b[0;32m   1625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 1626\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1627\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mand\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m dtype:\n\u001b[0;32m   1628\u001b[0m         x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mastype(dtype)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\imed\\Lib\\site-packages\\dask\\base.py:290\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    267\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[0;32m    268\u001b[0m \n\u001b[0;32m    269\u001b[0m \u001b[38;5;124;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;124;03m    dask.base.compute\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 290\u001b[0m     (result,) \u001b[38;5;241m=\u001b[39m \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\imed\\Lib\\site-packages\\dask\\base.py:573\u001b[0m, in \u001b[0;36mcompute\u001b[1;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[0;32m    570\u001b[0m     keys\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_keys__())\n\u001b[0;32m    571\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[1;32m--> 573\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\imed\\Lib\\site-packages\\dask\\threaded.py:81\u001b[0m, in \u001b[0;36mget\u001b[1;34m(dsk, result, cache, num_workers, pool, **kwargs)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pool, multiprocessing\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39mPool):\n\u001b[0;32m     79\u001b[0m         pool \u001b[38;5;241m=\u001b[39m MultiprocessingPoolExecutor(pool)\n\u001b[1;32m---> 81\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mget_async\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_max_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_thread_get_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpack_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpack_exception\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# Cleanup pools associated to dead threads\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pools_lock:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\imed\\Lib\\site-packages\\dask\\local.py:495\u001b[0m, in \u001b[0;36mget_async\u001b[1;34m(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\u001b[0m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwaiting\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mready\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrunning\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    494\u001b[0m     fire_tasks(chunksize)\n\u001b[1;32m--> 495\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, res_info, failed \u001b[38;5;129;01min\u001b[39;00m \u001b[43mqueue_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mresult():\n\u001b[0;32m    496\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m failed:\n\u001b[0;32m    497\u001b[0m             exc, tb \u001b[38;5;241m=\u001b[39m loads(res_info)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\imed\\Lib\\site-packages\\dask\\local.py:126\u001b[0m, in \u001b[0;36mqueue_get\u001b[1;34m(q)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 126\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Empty:\n\u001b[0;32m    128\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\imed\\Lib\\queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[0;32m    179\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m--> 180\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\imed\\Lib\\threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "from scipy.stats import gamma, norm\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "var=['TotalPrecip_tavg','Evap_tavg','Qs_tavg','RE','RE_cleaned']\n",
    "def calculate_spi(data):\n",
    "    # Post-processing to handle NaNs and zeros\n",
    "    data_n = data.copy()\n",
    "    data_n = data_n.fillna(data_n.mean())  # Fill NaNs with mean\n",
    "    data_n = xr.where(data_n == 0, 0.01, data_n)  # Replace zeros with 0.01\n",
    "\n",
    "    # Fit gamma distribution\n",
    "    shape, loc, scale = gamma.fit(data_n, floc=0)\n",
    "\n",
    "    # Calculate Probability of Exceedance (POE)\n",
    "    POE = 1 - gamma.cdf(data_n, shape, loc, scale)\n",
    "\n",
    "    # Calculate Standard Normal Variate (SNV) or Standardized Precipitation Index (SPI)\n",
    "    cdf_std = norm.cdf(norm.ppf(POE))\n",
    "    spi = norm.ppf(1 - cdf_std)\n",
    "\n",
    "    return spi\n",
    "\n",
    "\n",
    "result=[]\n",
    "for vr in var:\n",
    "\n",
    " ds=lsm_R_all[vr]\n",
    " spi = ds.groupby('time.month').apply(calculate_spi)\n",
    "\n",
    " # Create a new DataArray for SPI\n",
    " spi_ds = xr.DataArray(spi, coords=ds.coords, dims=ds.dims, name=f'SPI_{vr}')\n",
    " result.append(spi_ds)\n",
    "\n",
    "spi_reg = xr.merge(result)\n",
    "spi_reg.to_netcdf(f'DATA_p/LIS/{model[mdl]}/{model[mdl]}_reg_SPI1.nc')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
